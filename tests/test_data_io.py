import gzip
from unittest import mock

import duckdb
import requests

from oasis.core.backends.duckdb import DuckDBBackend
from oasis.core.datasets import DatasetDefinition, Modality
from oasis.data_io import (
    COMMON_USER_AGENT,
    _create_duckdb_with_views,
    _scrape_urls_from_html_page,
    compute_parquet_dir_size,
    convert_csv_to_parquet,
    init_duckdb_from_parquet,
    verify_table_rowcount,
)


def test_compute_parquet_dir_size_empty(tmp_path):
    size = compute_parquet_dir_size(tmp_path)
    assert size == 0


def test_verify_table_rowcount_with_temp_duckdb(tmp_path):
    db_path = tmp_path / "test.duckdb"
    con = duckdb.connect(str(db_path))
    try:
        con.execute("CREATE VIEW temp_numbers AS SELECT 1 AS x UNION ALL SELECT 2 AS x")
        con.commit()
    finally:
        con.close()

    count = verify_table_rowcount(db_path, "temp_numbers")
    assert count == 2


# ------------------------------------------------------------
# Scraping tests
# ------------------------------------------------------------


class DummyResponse:
    def __init__(self, content, status_code=200, headers=None):
        self.content = content.encode()
        self.status_code = status_code
        self.headers = headers or {}

    def raise_for_status(self):
        if not (200 <= self.status_code < 300):
            raise requests.exceptions.HTTPError(response=self)

    @property
    def reason(self):
        return "Error"

    def iter_content(self, chunk_size=1):
        yield from self.content


def test_scrape_urls(monkeypatch):
    html = (
        "<html><body>"
        '<a href="file1.csv.gz">ok</a>'
        '<a href="skip.txt">no</a>'
        "</body></html>"
    )
    dummy = DummyResponse(html)
    session = requests.Session()
    monkeypatch.setattr(session, "get", lambda url, timeout=None: dummy)
    urls = _scrape_urls_from_html_page("http://example.com/", session)
    assert urls == ["http://example.com/file1.csv.gz"]


def test_scrape_no_matching_suffix(monkeypatch):
    html = '<html><body><a href="file1.txt">ok</a></body></html>'
    dummy = DummyResponse(html)
    session = requests.Session()
    monkeypatch.setattr(session, "get", lambda url, timeout=None: dummy)
    urls = _scrape_urls_from_html_page("http://example.com/", session)
    assert urls == []


def test_common_user_agent_header():
    # Ensure the constant is set and looks like a UA string
    assert isinstance(COMMON_USER_AGENT, str)
    assert "Mozilla/" in COMMON_USER_AGENT


# ------------------------------------------------------------
# CSV -> Parquet conversion and DuckDB init tests
# ------------------------------------------------------------


def _write_gz_csv(path, text):
    with gzip.open(path, "wt", encoding="utf-8") as f:
        f.write(text)


def test_convert_csv_to_parquet_and_init_duckdb(tmp_path, monkeypatch):
    # Prepare a minimal CSV.gz (root-level for vf-ghana style)
    src_root = tmp_path / "src"
    src_root.mkdir(parents=True, exist_ok=True)
    csv_gz = src_root / "facilities.csv.gz"

    _write_gz_csv(
        csv_gz,
        "pk_unique_id,name\n"  # header
        "1,Tamale Teaching Hospital\n"
        "2,Korle Bu Teaching Hospital\n",
    )

    # Convert to Parquet under dst root
    dst_root = tmp_path / "parquet"
    ok = convert_csv_to_parquet("vf-ghana", src_root, dst_root)
    assert ok  # conversion succeeded

    out_parquet = dst_root / "facilities.parquet"
    assert out_parquet.exists()  # parquet file created

    # Quick verify via DuckDB
    con = duckdb.connect()
    try:
        cnt = con.execute(
            f"SELECT COUNT(*) FROM read_parquet('{out_parquet.as_posix()}')"
        ).fetchone()[0]
    finally:
        con.close()
    assert cnt == 2  # two data rows

    # Initialize DuckDB views, patching the parquet root resolver.
    # vf-ghana has schema_mapping {"": "vf"},
    # so views are schema-qualified: vf.facilities
    db_path = tmp_path / "test.duckdb"
    with mock.patch("oasis.data_io.get_dataset_parquet_root", return_value=dst_root):
        init_ok = init_duckdb_from_parquet("vf-ghana", db_path)
    assert init_ok  # views created

    # Query the schema-qualified view
    con = duckdb.connect(str(db_path))
    try:
        cnt = con.execute("SELECT COUNT(*) FROM vf.facilities").fetchone()[0]
    finally:
        con.close()
    assert cnt == 2


# ------------------------------------------------------------
# Schema mapping tests
# ------------------------------------------------------------


def _create_parquet(directory, filename, csv_text):
    """Helper: write a CSV.gz, convert to parquet, return path."""
    directory.mkdir(parents=True, exist_ok=True)
    csv_gz = directory / f"{filename}.csv.gz"
    _write_gz_csv(csv_gz, csv_text)
    parquet_path = directory / f"{filename}.parquet"
    con = duckdb.connect()
    try:
        con.execute(
            f"COPY (SELECT * FROM read_csv_auto('{csv_gz.as_posix()}')) "
            f"TO '{parquet_path.as_posix()}' (FORMAT PARQUET)"
        )
    finally:
        con.close()
    return parquet_path


def test_schema_mapping_root_level(tmp_path):
    """Root-level parquet files with {"": "vf"} mapping produce
    vf.table views (VF Ghana style)."""
    parquet_root = tmp_path / "parquet"
    _create_parquet(
        parquet_root, "facilities", "pk_unique_id,name\n1,Hospital A\n2,Hospital B\n"
    )

    db_path = tmp_path / "test.duckdb"
    mapping = {"": "vf"}
    ok = _create_duckdb_with_views(db_path, parquet_root, schema_mapping=mapping)
    assert ok

    con = duckdb.connect(str(db_path))
    try:
        cnt = con.execute("SELECT COUNT(*) FROM vf.facilities").fetchone()[0]
        assert cnt == 2
    finally:
        con.close()


def test_schema_mapping_subdirectory(tmp_path):
    """Parquet files in subdirectories with schema_mapping produce
    schema-qualified DuckDB views."""
    parquet_root = tmp_path / "parquet"
    _create_parquet(
        parquet_root / "data",
        "facilities",
        "pk_unique_id,name\n1,Hospital A\n2,Hospital B\n",
    )

    db_path = tmp_path / "test.duckdb"
    mapping = {"data": "vf"}
    ok = _create_duckdb_with_views(db_path, parquet_root, schema_mapping=mapping)
    assert ok

    con = duckdb.connect(str(db_path))
    try:
        # Schema exists
        schemas = [
            r[0]
            for r in con.execute(
                "SELECT schema_name FROM information_schema.schemata"
            ).fetchall()
        ]
        assert "vf" in schemas

        # View is schema-qualified
        cnt = con.execute("SELECT COUNT(*) FROM vf.facilities").fetchone()[0]
        assert cnt == 2
    finally:
        con.close()


def test_no_schema_mapping_flat_naming(tmp_path):
    """Without schema_mapping, views use flat naming (backward compat)."""
    parquet_root = tmp_path / "parquet"
    _create_parquet(
        parquet_root / "data",
        "facilities",
        "pk_unique_id,name\n1,Hospital A\n",
    )

    db_path = tmp_path / "test.duckdb"
    ok = _create_duckdb_with_views(db_path, parquet_root, schema_mapping=None)
    assert ok

    con = duckdb.connect(str(db_path))
    try:
        cnt = con.execute("SELECT COUNT(*) FROM data_facilities").fetchone()[0]
        assert cnt == 1
    finally:
        con.close()


# ------------------------------------------------------------
# Round-trip integration test: parquet -> DuckDB -> backend API
# ------------------------------------------------------------


def test_roundtrip_parquet_to_backend_api(tmp_path):
    """End-to-end: create parquet, init DuckDB with schema_mapping,
    then verify get_table_list / get_table_info / get_sample_data
    all work through the DuckDBBackend API."""
    parquet_root = tmp_path / "parquet"
    _create_parquet(
        parquet_root,
        "facilities",
        "pk_unique_id,name,number_beds\n1,Tamale Teaching Hospital,200\n2,Korle Bu Teaching Hospital,1600\n",
    )

    mapping = {"": "vf"}
    db_path = tmp_path / "roundtrip.duckdb"
    ok = _create_duckdb_with_views(db_path, parquet_root, schema_mapping=mapping)
    assert ok

    ds = DatasetDefinition(
        name="roundtrip-test",
        modalities=frozenset({Modality.TABULAR}),
        schema_mapping=mapping,
    )
    backend = DuckDBBackend(db_path_override=db_path)

    # get_table_list returns schema-qualified names
    tables = backend.get_table_list(ds)
    assert "vf.facilities" in tables

    # get_table_info works for schema-qualified names
    info = backend.get_table_info("vf.facilities", ds)
    assert info.success is True
    col_names = info.dataframe["name"].tolist()
    assert "pk_unique_id" in col_names
    assert "name" in col_names

    # get_sample_data works for schema-qualified names
    sample = backend.get_sample_data("vf.facilities", ds, limit=1)
    assert sample.success is True
    assert sample.row_count <= 1
    assert "pk_unique_id" in sample.dataframe.columns
